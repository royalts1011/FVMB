{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - Deformable Image Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1  - Image gradients and diffusion regularisation \n",
    "\n",
    "At first we import relevant python functions. Functions for laplace matrices, conjugate gradients as well as a function for visualizing deformation fields are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors as mcolors\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "def laplace(lambda_weight,H,W):\n",
    "    xy = torch.arange(H*W).view(H,W)\n",
    "    i1 = torch.cat((xy[1:,:].view(1,-1),xy[:-1,:].view(1,-1)),0)\n",
    "    i2 = torch.cat((xy[:-1,:].view(1,-1),xy[1:,:].view(1,-1)),0)\n",
    "    i3 = torch.cat((xy[:,1:].contiguous().view(1,-1),xy[:,:-1].contiguous().view(1,-1)),0)\n",
    "    i4 = torch.cat((xy[:,:-1].contiguous().view(1,-1),xy[:,1:].contiguous().view(1,-1)),0)\n",
    "\n",
    "    A = lambda_weight * torch.sparse.FloatTensor(torch.cat((i1,i2,i3,i4),1), -torch.ones(2*(2*H*W-H-W)), torch.Size([H*W,H*W]))#\n",
    "    D = torch.spmm(A,-torch.ones(H*W,1)).view(-1)# + diag.view(-1) #row-sum + input diagonal\n",
    "    D = torch.sparse.FloatTensor(torch.stack((torch.arange(H*W),torch.arange(H*W)),0), D, torch.Size([H*W,H*W]))\n",
    "    L = D + A \n",
    "    return L\n",
    "\n",
    "def sparseCG(A,b,iterations): #A sparse matrix, b dense vector\n",
    "#conjugate gradient https://william-dawson.github.io/blog/method/2017/10/01/matrixcg.html\n",
    "    x = torch.zeros(b.numel(),1)\n",
    "    r = b.view(-1,1) - torch.spmm(A,x)\n",
    "    p = r.clone()\n",
    "    for i in range(iterations):\n",
    "        Ap = torch.spmm(A,p)\n",
    "        top = (r*r).sum()\n",
    "        bottom = (p*Ap).sum()\n",
    "        alpha = top / bottom\n",
    "        x = x + alpha * p\n",
    "        r = r - alpha * Ap\n",
    "\n",
    "        #norm_value = torch.norm(r)\n",
    "        #if norm_value < 1e-8:\n",
    "        #    break\n",
    "        new_top = (r*r).sum()\n",
    "        beta = new_top/top\n",
    "        p = r + beta * p\n",
    "    #print(\"Done:\", i, norm_value)\n",
    "    return x\n",
    "\n",
    "# showFlow: transforms deformation field into a rgb image\n",
    "# input: numpy.array, H x W x C(numdims), should be on cpu (check with def_x.device)\n",
    "def showFlow(def_x):\n",
    "    x = def_x.squeeze().numpy()[0,:,:]\n",
    "    y = def_x.squeeze().numpy()[1,:,:]\n",
    "    #show flow map for numpy\n",
    "    H, W = x.shape\n",
    "    rho = np.sqrt(x*x+y*y)\n",
    "    theta = np.arctan2(x,-y)\n",
    "    theta2 = (-theta+np.pi)/(2.0*np.pi)\n",
    "    rho = np.clip(rho/np.percentile(rho, 99),0,1)\n",
    "    hsv = np.stack((theta2,rho,np.ones((H,W))),axis=2)\n",
    "    rgb = mcolors.hsv_to_rgb(hsv)\n",
    "    return rgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and reformat input data (fixed and moving image)\n",
    "\n",
    "images = torch.load('images_flow.pth')\n",
    "fixed = images[0:1].unsqueeze(1)\n",
    "moving = images[1:2].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nSolution by: Falco Lentzsch(685454),Konrad von Kuegelgen, Jesse Kruse(675710)\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Solution by: Falco Lentzsch(685454),Konrad von Kuegelgen, Jesse Kruse(675710)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m lambda_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m750\u001B[39m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# generate laplace matrix (given)\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m L \u001B[38;5;241m=\u001B[39m \u001B[43mlaplace\u001B[49m(lambda_weight, H, W)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# todo: calculate the two-point stencil\u001B[39;00m\n\u001B[1;32m     20\u001B[0m weight \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m.5\u001B[39m, \u001B[38;5;241m.5\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m lambda_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m750\u001B[39m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# generate laplace matrix (given)\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m L \u001B[38;5;241m=\u001B[39m \u001B[43mlaplace\u001B[49m(lambda_weight, H, W)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# todo: calculate the two-point stencil\u001B[39;00m\n\u001B[1;32m     20\u001B[0m weight \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m.5\u001B[39m, \u001B[38;5;241m.5\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1180\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:621\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:930\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:921\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:318\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1147\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1144\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1162\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1159\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1161\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1162\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Implement tasks 1 & 2\n",
    "'''\n",
    "Hier started Aufgabe 1\n",
    "'''\n",
    "\n",
    "# H und W auslesen\n",
    "H,W = fixed.size()[-2:]\n",
    "# Größe des Bildes erstellen\n",
    "xy = torch.arange(H*W)\n",
    "# Größe für Sparse Matrix\n",
    "size = (H * W, H * W)\n",
    "# Indices für Diagonale auf Sparse Matrix\n",
    "indices = torch.stack([xy,xy],0)\n",
    "# Gewichtungsfaktor für La Place Matrix\n",
    "lambda_weight = 750\n",
    "# generate laplace matrix (given)\n",
    "L = laplace(lambda_weight, H, W)\n",
    "\n",
    "# todo: calculate the two-point stencil\n",
    "weight = torch.linspace(-.5, .5, 3)\n",
    "Mx_weights = weight.view(1, 1, 1, 3)\n",
    "My_weights = weight.view(1, 1, 3, 1)\n",
    "\n",
    "# Moving Image wird gepadded, damit die Größe gleich bleibt durch die Faltung\n",
    "Mx_pad_input = F.pad(moving, [1, 1, 0, 0], 'replicate')\n",
    "My_pad_input = F.pad(moving, [0, 0, 1, 1], 'replicate')\n",
    "\n",
    "# Bild filtern in x und y Richtung liefert Gradientenfeld\n",
    "Mx_gradient = F.conv2d(input=Mx_pad_input,weight=Mx_weights)\n",
    "My_gradient = F.conv2d(input=My_pad_input,weight=My_weights)\n",
    "\n",
    "# Gradientenfeld als Vektor und quadriert\n",
    "Mx_gradient_diag_squared = torch.pow(Mx_gradient.view(-1), 2)\n",
    "My_gradient_diag_squared = torch.pow(My_gradient.view(-1), 2)\n",
    "\n",
    "# Eintragen der quadrierten Gradienten auf der Diagonalen unserer Sparse Matrix\n",
    "Mxx = torch.sparse_coo_tensor(indices=indices,values=Mx_gradient_diag_squared,size=size)\n",
    "Myy = torch.sparse_coo_tensor(indices=indices,values=My_gradient_diag_squared,size=size)\n",
    "\n",
    "# Rechte Seite der Gleichung wird erstellt\n",
    "# MM zwischen L und u fällt weg, da u^0 = 0\n",
    "bx = -(moving-fixed) * Mx_gradient\n",
    "by = -(moving-fixed) * My_gradient\n",
    "\n",
    "# todo: create vectors u,v --> Verschiebungsfeld\n",
    "u = sparseCG(L + Mxx, bx, 25).view(H, W)\n",
    "v = sparseCG(L + Myy, by, 25).view(H, W)\n",
    "\n",
    "\n",
    "'''\n",
    "Hier started Aufgabe 2\n",
    "'''\n",
    "# generate identity grid using F.affine_grid\n",
    "# Erstellen hier ein Grid mit 6 Freiheitsgraden wobei wir es\n",
    "# Standartmäßig so initialisieren, das das grid nichts verändert\n",
    "identity_grid = F.affine_grid(torch.eye(2, 3).unsqueeze(0), [1, 1, H, W], True)\n",
    "# stacked and reshaped uv im Bereich zwischen -1 und 1\n",
    "uv = torch.stack([u / (.5 * (H - 1)), v / (.5 * (W - 1))], 2).unsqueeze(0)\n",
    "\n",
    "# Addieren von UV udn Grid liefert ein Transformationsfeld\n",
    "mapped_uv_field = identity_grid + uv\n",
    "warped = F.grid_sample(moving, mapped_uv_field, align_corners=True)\n",
    "\n",
    "# For-loop for iterative warping\n",
    "for i in range(10):\n",
    "    # Padding des warped Bildes nicht, da neues moving image\n",
    "    Mx_pad_input = F.pad(warped, [1, 1, 0, 0], 'replicate')\n",
    "    My_pad_input = F.pad(warped, [0, 0, 1, 1], 'replicate')\n",
    "    # todo: Apply the gradient filter using 2d-convolution\n",
    "    Mx_gradient = F.conv2d(input=Mx_pad_input,weight=Mx_weights)\n",
    "    My_gradient = F.conv2d(input=My_pad_input,weight=My_weights)\n",
    "\n",
    "\n",
    "    # Gradientenfeld als Vektor und quadriert\n",
    "    Mx_gradient_diag_squared = torch.pow(Mx_gradient.view(-1), 2)\n",
    "    My_gradient_diag_squared = torch.pow(My_gradient.view(-1), 2)\n",
    "\n",
    "    # todo: Create Sparse Matrices containing pointwise squared gradients\n",
    "    # Eintragen der quadrierten Gradienten auf der Diagonalen unserer Sparse Matrix\n",
    "    Mxx = torch.sparse_coo_tensor(indices=indices,values=Mx_gradient_diag_squared,size=size)\n",
    "    Myy = torch.sparse_coo_tensor(indices=indices,values=My_gradient_diag_squared,size=size)\n",
    "\n",
    "    # todo: Create tensors bx,by\n",
    "    # Rechte Seite der Gleichung wird erstellt\n",
    "    #bx = -(warped-fixed) * Mx_gradient\n",
    "    #by = -(warped-fixed) * My_gradient\n",
    "    bx = - torch._sparse_mm(L, u.view(-1, 1)).view(H, W) -(warped - fixed) * Mx_gradient\n",
    "    by = - torch._sparse_mm(L, v.view(-1, 1)).view(H, W) -(warped - fixed) * My_gradient\n",
    "\n",
    "    # todo: Solve u,v (separately) and stack accordingly to uv\n",
    "    u += sparseCG(L + Mxx, bx, 25).view(H, W)\n",
    "    v += sparseCG(L + Myy, by, 25).view(H, W)\n",
    "    uv = torch.stack([u / (.5 * (H - 1)), v / (.5 * (W - 1))], 2).unsqueeze(0)\n",
    "\n",
    "    # todo: warp Image using F:grid_sample with identity grid (task 2)\n",
    "    mapped_uv_field = identity_grid + uv\n",
    "    warped = F.grid_sample(moving, mapped_uv_field, align_corners=True)\n",
    "\n",
    "'''\n",
    "Visualisierung\n",
    "'''\n",
    "\n",
    "plt.imshow((fixed-warped).squeeze().numpy(),'gray')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "rgb = showFlow(torch.stack((u,v),0))\n",
    "\n",
    "plt.imshow(rgb)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39minterpolate(x,scale_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m,mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbilinear\u001B[39m\u001B[38;5;124m'\u001B[39m,align_corners\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     16\u001B[0m net \u001B[38;5;241m=\u001B[39m DeformableNet()\n\u001B[0;32m---> 17\u001B[0m disp_x \u001B[38;5;241m=\u001B[39m \u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m H,W \u001B[38;5;241m=\u001B[39m fixed\u001B[38;5;241m.\u001B[39msize()[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:]\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# todo: create identity grid\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/FVMB/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36mDeformableNet.forward\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     13\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbspline(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ma)\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241m.\u001B[39minterpolate(x,scale_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m,mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbilinear\u001B[39m\u001B[38;5;124m'\u001B[39m,align_corners\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36mDeformableNet.forward\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     13\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbspline(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ma)\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241m.\u001B[39minterpolate(x,scale_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m,mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbilinear\u001B[39m\u001B[38;5;124m'\u001B[39m,align_corners\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1180\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:621\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:930\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:921\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:318\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1147\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1144\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1162\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1159\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1161\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1162\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "class DeformableNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeformableNet, self).__init__()\n",
    "        self.a = nn.Parameter(0.0*torch.randn(1,2,51,38))\n",
    "        self.bspline = nn.Sequential(\n",
    "            nn.ZeroPad2d(6),\n",
    "            nn.AvgPool2d(5,stride=1),\n",
    "            nn.AvgPool2d(5,stride=1),\n",
    "            nn.AvgPool2d(5,stride=1))\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        x = self.bspline(self.a)\n",
    "        return F.interpolate(x,scale_factor=6,mode='bilinear',align_corners=True)\n",
    "\n",
    "net = DeformableNet()\n",
    "disp_x = net()\n",
    "\n",
    "H,W = fixed.size()[-2:]\n",
    "\n",
    "# todo: create identity grid\n",
    "identity_grid = F.affine_grid(torch.eye(2, 3).unsqueeze(0), [1, 1, H, W], True)\n",
    "\n",
    "# given: initialization of adam and bspline definition\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.015)\n",
    "#bspline = nn.Sequential(nn.ZeroPad2d(6),nn.AvgPool2d(5,stride=1),nn.AvgPool2d(5,stride=1),nn.AvgPool2d(5,stride=1))\n",
    "\n",
    "\n",
    "\n",
    "# Defintion of NCC los\n",
    "# given: weights, mean and variance for fixed image\n",
    "K = 5\n",
    "kw = (K-1)//2\n",
    "N = F.avg_pool2d(torch.ones_like(moving),K,stride=1,padding=kw).sum()\n",
    "fixed_mean = F.avg_pool2d(fixed,K,stride=1,padding=kw)/N\n",
    "fixed_var = F.avg_pool2d(fixed**2,K,stride=1,padding=kw)/N-fixed_mean**2\n",
    "\n",
    "def NCC(moving_image):\n",
    "    moving = moving_image\n",
    "    moving_mean = F.avg_pool2d(moving,K,stride=1,padding=kw)/N\n",
    "    moving_var = F.avg_pool2d(moving**2,K,stride=1,padding=kw)/N-moving_mean**2\n",
    "\n",
    "\n",
    "    #cov = (F.avg_pool2d(moving,K,stride=1,padding=kw) - moving_mean) \\\n",
    "    #      * (F.avg_pool2d(fixed,K,stride=1,padding=kw) - fixed_mean)\n",
    "\n",
    "    # soll laut Übung so gemacht werden\n",
    "    cov_2 = F.avg_pool2d(moving * fixed,K,stride=1,padding=kw) \\\n",
    "          - F.avg_pool2d(moving,K,stride=1,padding=kw) * fixed_mean \\\n",
    "          - moving_mean * (F.avg_pool2d(fixed,K,stride=1,padding=kw)) \\\n",
    "          + moving_mean * fixed_mean\n",
    "\n",
    "\n",
    "    #covariance = avg_kernel(moving * fixed) - avg_kernel(moving) * fixed_mean \\\n",
    "                #- avg_kernel(fixed) * moving_mean + moving_mean * fixed_mean\n",
    "    # https://stackoverflow.com/questions/40050397/deep-learning-nan-loss-reasons\n",
    "    # cov wird hier quadriert, da die ganze Gleichung quadriert werden soll\n",
    "    # die beiden Varianzen sollten eigtl in der Formel Standartabweichungensein.\n",
    "    # Da wir aber quadrieren sollen, lassen wir diese hier so\n",
    "    # 1e-8 bei Stackoverflow nach zu lesen, damit es nicht passieren kann das wir durch 0 Teilen.\n",
    "    ncc =  - torch.sum(cov_2.pow(2) / (moving_var * fixed_var))\n",
    "\n",
    "    return ncc\n",
    "\n",
    "\n",
    "# definde loss\n",
    "mse_Loss = nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "# given: Optimisation loop\n",
    "for i in range(0,100):\n",
    "    # todo: Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # given :Execute the model to obtain displacements\n",
    "    disp_x = net()\n",
    "    # todo: call function for bilinear upsampling (scaling of 6)\n",
    "\n",
    "    # todo: Warp image\n",
    "    mapped_uv_field = identity_grid + disp_x.permute(0,2,3,1)\n",
    "    warped = F.grid_sample(moving, mapped_uv_field, align_corners=True)\n",
    "\n",
    "    # todo: Compute Mean Squared Error for loss criteria\n",
    "\n",
    "    #loss = mse_Loss(warped, fixed) # --> use this for MSE\n",
    "    loss = NCC(warped) # --> use this for NCC\n",
    "    print(\"Loss in Epoche \", i , \":\", loss.data)\n",
    "\n",
    "    # todo: (Bonus) Compute Normalised Cross Correlation for loss criteria\n",
    "\n",
    "    # todo: Compute gradients of the loss w.r.t. the parameters of our model (-> backward).\n",
    "    loss.backward()\n",
    "    # todo: Update the parameters based on the calculated gradients.\n",
    "    optimizer.step()\n",
    "# Visualization\n",
    "rgb_nn = showFlow(disp_x.data.cpu())\n",
    "plt.imshow(rgb_nn)\n",
    "plt.show()\n",
    "\n",
    "warped = F.grid_sample(moving,disp_x.permute(0,2,3,1)+identity_grid,align_corners=True,padding_mode='border')\n",
    "plt.imshow((moving-fixed).data.cpu().squeeze(),'gray')\n",
    "plt.show()\n",
    "plt.imshow((warped-fixed).data.cpu().squeeze(),'gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}